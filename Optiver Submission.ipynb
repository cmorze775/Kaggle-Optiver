{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "from xgboost import XGBRegressor\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('input/optiver-realized-volatility-prediction/train.csv')\n",
    "test = pd.read_csv('input/optiver-realized-volatility-prediction/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_return(list_stock_prices):\n",
    "    return np.log(list_stock_prices).diff() \n",
    "\n",
    "def realized_volatility(series_log_return):\n",
    "    return np.sqrt(np.sum(series_log_return**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_order_book_file_train = glob.glob('input/optiver-realized-volatility-prediction/book_train.parquet/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(folder_path):\n",
    "    df_all=[]\n",
    "    for file in tqdm(folder_path):\n",
    "        stock_id = file.split('=')[1]\n",
    "        df_book_data = pd.read_parquet(file)\n",
    "        df_book_data['wap'] =(df_book_data['bid_price1'] * df_book_data['ask_size1']+df_book_data['ask_price1'] * df_book_data['bid_size1'])  / (df_book_data['bid_size1']+ df_book_data['ask_size1'])\n",
    "        df_book_data['wap2'] =(df_book_data['bid_price2'] * df_book_data['ask_size2']+df_book_data['ask_price2'] * df_book_data['bid_size2'])  / (df_book_data['bid_size2']+ df_book_data['ask_size2'])\n",
    "        df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
    "        df_book_data['log_return2'] = df_book_data.groupby(['time_id'])['wap2'].apply(log_return)\n",
    "        df_book_data['row_id'] = df_book_data['time_id'].apply(lambda x:f'{stock_id}-{x}')\n",
    "        \n",
    "        df_book_data['price_diff'] = (df_book_data['ask_price1'] - df_book_data['bid_price1']) / ((df_book_data['ask_price1'] + df_book_data['bid_price1']) / 2)\n",
    "        df_book_data['price_diff2'] = (df_book_data['ask_price2'] - df_book_data['bid_price2']) / ((df_book_data['ask_price2'] + df_book_data['bid_price2']) / 2)\n",
    "        df_book_data['bid_diff'] = df_book_data['bid_price1'] - df_book_data['bid_price2']\n",
    "        df_book_data['ask_diff'] = df_book_data['ask_price1'] - df_book_data['ask_price2']\n",
    "        df_book_data['bid_ask_diff'] = abs(df_book_data['bid_diff'] - df_book_data['ask_diff'])\n",
    "        df_book_data['total_volm'] = (df_book_data['ask_size1'] + df_book_data['ask_size2']) + (df_book_data['bid_size1'] + df_book_data['bid_size2'])\n",
    "        df_book_data['volume_imbal'] = abs((df_book_data['ask_size1'] + df_book_data['ask_size2']) - (df_book_data['bid_size1'] + df_book_data['bid_size2']))\n",
    "        \n",
    "        create_feature_dict = {\n",
    "        'wap': [np.sum, np.mean, np.std],\n",
    "        'wap2': [np.sum, np.mean, np.std],\n",
    "        'log_return': [np.sum, realized_volatility, np.mean, np.std],\n",
    "        'log_return2': [np.sum, realized_volatility, np.mean, np.std],\n",
    "        'price_diff':[np.sum, np.mean, np.std],\n",
    "        'bid_diff':[np.sum, np.mean, np.std],\n",
    "        'ask_diff':[np.sum, np.mean, np.std],\n",
    "        'total_volm':[np.sum, np.mean, np.std],\n",
    "        'volume_imbal':[np.sum, np.mean, np.std]\n",
    "        }\n",
    "        \n",
    "        def get_stats_window(seconds_in_bucket, add_suffix = False):\n",
    "            # Group by the window\n",
    "            df_feature = df_book_data[df_book_data['seconds_in_bucket'] >= seconds_in_bucket].groupby(['time_id']).agg(create_feature_dict).reset_index()\n",
    "            # Rename columns joining suffix\n",
    "            df_feature.columns = ['_'.join(col) for col in df_feature.columns]\n",
    "            # Add a suffix to differentiate windows\n",
    "            if add_suffix:\n",
    "                df_feature = df_feature.add_suffix('_' + str(seconds_in_bucket))\n",
    "            return df_feature\n",
    "    \n",
    "        df_feature = get_stats_window(seconds_in_bucket = 0, add_suffix = False)\n",
    "        df_feature_450 = get_stats_window(seconds_in_bucket = 450, add_suffix = True)\n",
    "        df_feature_300 = get_stats_window(seconds_in_bucket = 300, add_suffix = True)\n",
    "        df_feature_150 = get_stats_window(seconds_in_bucket = 150, add_suffix = True)\n",
    "    \n",
    "        df_feature = df_feature.merge(df_feature_450, how = 'left', left_on = 'time_id_', right_on = 'time_id__450')\n",
    "        df_feature = df_feature.merge(df_feature_300, how = 'left', left_on = 'time_id_', right_on = 'time_id__300')\n",
    "        df_feature = df_feature.merge(df_feature_150, how = 'left', left_on = 'time_id_', right_on = 'time_id__150')\n",
    "        # Drop unnecesary time_ids\n",
    "        df_feature.drop(['time_id__450', 'time_id__300', 'time_id__150'], axis = 1, inplace = True)\n",
    "        stock_id = file.split('=')[1]\n",
    "        df_feature['row_id'] = df_feature['time_id_'].apply(lambda x: f'{stock_id}-{x}')\n",
    "        df_feature.drop(['time_id_'], axis = 1, inplace = True)\n",
    "        df_all.append(df_feature)\n",
    "    return pd.concat(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = processing(list_order_book_file_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_order_trade_file_train = glob.glob('input/optiver-realized-volatility-prediction/trade_train.parquet/*')\n",
    "#list_order_trade_file_train = list_order_trade_file_train[0:3]\n",
    "\n",
    "# Function to count unique elements of a series\n",
    "def count_unique(series):\n",
    "    return len(np.unique(series))\n",
    "\n",
    "# Function to preprocess trade data (for each stock id)\n",
    "def trade_preprocessor(folder_path):\n",
    "    df_all = []\n",
    "    for file in tqdm(folder_path):\n",
    "        df = pd.read_parquet(file)\n",
    "        df['log_return'] = df.groupby('time_id')['price'].apply(log_return)\n",
    "\n",
    "        # Dict for aggregations\n",
    "        create_feature_dict = {\n",
    "            'log_return':[realized_volatility],\n",
    "            'seconds_in_bucket':[count_unique],\n",
    "            'size':[np.sum],\n",
    "            'order_count':[np.mean],\n",
    "        }\n",
    "\n",
    "        # Function to get group stats for different windows (seconds in bucket)\n",
    "        def get_stats_window(seconds_in_bucket, add_suffix = False):\n",
    "            # Group by the window\n",
    "            df_feature = df[df['seconds_in_bucket'] >= seconds_in_bucket].groupby(['time_id']).agg(create_feature_dict).reset_index()\n",
    "            # Rename columns joining suffix\n",
    "            df_feature.columns = ['_'.join(col) for col in df_feature.columns]\n",
    "            # Add a suffix to differentiate windows\n",
    "            if add_suffix:\n",
    "                df_feature = df_feature.add_suffix('_' + str(seconds_in_bucket))\n",
    "            return df_feature\n",
    "\n",
    "        # Get the stats for different windows\n",
    "        df_feature = get_stats_window(seconds_in_bucket = 0, add_suffix = False)\n",
    "        df_feature_450 = get_stats_window(seconds_in_bucket = 450, add_suffix = True)\n",
    "        df_feature_300 = get_stats_window(seconds_in_bucket = 300, add_suffix = True)\n",
    "        df_feature_150 = get_stats_window(seconds_in_bucket = 150, add_suffix = True)\n",
    "\n",
    "        # Merge all\n",
    "        df_feature = df_feature.merge(df_feature_450, how = 'left', left_on = 'time_id_', right_on = 'time_id__450')\n",
    "        df_feature = df_feature.merge(df_feature_300, how = 'left', left_on = 'time_id_', right_on = 'time_id__300')\n",
    "        df_feature = df_feature.merge(df_feature_150, how = 'left', left_on = 'time_id_', right_on = 'time_id__150')\n",
    "        # Drop unnecesary time_ids\n",
    "        df_feature.drop(['time_id__450', 'time_id__300', 'time_id__150'], axis = 1, inplace = True)\n",
    "\n",
    "        df_feature = df_feature.add_prefix('trade_')\n",
    "        stock_id = file.split('=')[1]\n",
    "        df_feature['row_id'] = df_feature['trade_time_id_'].apply(lambda x:f'{stock_id}-{x}')\n",
    "        df_feature.drop(['trade_time_id_'], axis = 1, inplace = True)\n",
    "        df_all.append(df_feature)\n",
    "    return pd.concat(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_2 = trade_preprocessor(list_order_trade_file_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.merge(df_train_2,how='left',on=['row_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[['stock_id','time_id']] = pd.DataFrame(df_train['row_id'].str.split('-').to_list(),index=df_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get realized volatility columns\n",
    "vol_cols = ['log_return_realized_volatility', 'log_return2_realized_volatility', 'log_return_realized_volatility_450', 'log_return2_realized_volatility_450', \n",
    "            'log_return_realized_volatility_300', 'log_return2_realized_volatility_300', 'log_return_realized_volatility_150', 'log_return2_realized_volatility_150', \n",
    "            'trade_log_return_realized_volatility', 'trade_log_return_realized_volatility_450', 'trade_log_return_realized_volatility_300', 'trade_log_return_realized_volatility_150']\n",
    "\n",
    "# Group by the stock id\n",
    "df_stock_id = df_train.groupby(['stock_id'])[vol_cols].agg(['mean', 'std', 'max', 'min', ]).reset_index()\n",
    "# Rename columns joining suffix\n",
    "df_stock_id.columns = ['_'.join(col) for col in df_stock_id.columns]\n",
    "df_stock_id = df_stock_id.add_suffix('_' + 'stock')\n",
    "\n",
    "# Group by the stock id\n",
    "df_time_id = df_train.groupby(['time_id'])[vol_cols].agg(['mean', 'std', 'max', 'min', ]).reset_index()\n",
    "# Rename columns joining suffix\n",
    "df_time_id.columns = ['_'.join(col) for col in df_time_id.columns]\n",
    "df_time_id = df_time_id.add_suffix('_' + 'time')\n",
    "\n",
    "# Merge with original dataframe\n",
    "df_train = df_train.merge(df_stock_id, how = 'left', left_on = ['stock_id'], right_on = ['stock_id__stock'])\n",
    "df_train = df_train.merge(df_time_id, how = 'left', left_on = ['time_id'], right_on = ['time_id__time'])\n",
    "df_train.drop(['stock_id__stock', 'time_id__time'], axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ToWeight(y):\n",
    "    w = np.zeros(y.shape, dtype=float)\n",
    "    ind = y != 0\n",
    "    w[ind] = 1./(y[ind]**2)\n",
    "    return w\n",
    "\n",
    "\n",
    "def rmspe(yhat, y):\n",
    "    w = ToWeight(y)\n",
    "    rmspe = np.sqrt(np.mean( w * (y - yhat)**2 ))\n",
    "    return rmspe\n",
    "\n",
    "\n",
    "def rmspe_xg(yhat, y):\n",
    "    # y = y.values\n",
    "    y = y.get_label()\n",
    "    y = np.exp(y) - 1\n",
    "    yhat = np.exp(yhat) - 1\n",
    "    w = ToWeight(y)\n",
    "    rmspe = np.sqrt(np.mean(w * (y - yhat)**2))\n",
    "    return \"rmspe\", rmspe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['row_id'] = train['stock_id'].astype(str)+'-'+train['time_id'].astype(str)\n",
    "df_train[['stock_id','time_id']] = df_train[['stock_id','time_id']].astype(int)\n",
    "train = train.merge(df_train,how='left',on=['row_id','stock_id','time_id'])\n",
    "columns = train.drop(columns=['stock_id','time_id','target','row_id']).columns\n",
    "train[columns] = train[columns].astype(float)\n",
    "train = train.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "train = train.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = train.drop(columns=['stock_id','time_id','target','row_id']).columns\n",
    "X_train, X_test, y_train, y_test = train_test_split(train.drop(columns=['target']),train['target'],random_state=42,test_size = .025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'colsample_bytree': 0.7, \n",
    "          'learning_rate': 0.05, \n",
    "          'max_depth': 8, \n",
    "          'min_child_weight': 4, \n",
    "          'n_estimators': 10000, \n",
    "          'nthread': 4, \n",
    "          'objective': 'reg:squaredlogerror', \n",
    "          'subsample': 0.7, \n",
    "          'tree_method': 'gpu_hist'\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(**params, feval=rmspe_xg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.7,\n",
       "             feval=<function rmspe_xg at 0x000001B5505A70D0>, gamma=0, gpu_id=0,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.05, max_delta_step=0, max_depth=8,\n",
       "             min_child_weight=4, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=10000, n_jobs=4, nthread=4, num_parallel_tree=1,\n",
       "             objective='reg:squaredlogerror', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=0.7,\n",
       "             tree_method='gpu_hist', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train[columns],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_preds = model.predict(X_test[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "def rmspe(y_true, y_pred):\n",
    "    return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))\n",
    "R2 = round(r2_score(y_true = y_test, y_pred = xg_preds),3)\n",
    "RMSPE = round(rmspe(y_true = y_test, y_pred = xg_preds),3)\n",
    "print(f' R2 score: {R2}, RMSPE: {RMSPE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\conno\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:537: UserWarning: kwargs is not saved in Scikit-Learn meta.\n",
      "  warnings.warn(str(k) + ' is not saved in Scikit-Learn meta.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "model.save_model('optiverv4.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GeForce RTX 2060 SUPER\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert training date to tensors\n",
    "X_nn = torch.FloatTensor(np.array(X_train[columns]))\n",
    "X_nn_1 = X_train[['stock_id']].copy().values.astype(np.int64)\n",
    "y_nn = torch.FloatTensor(np.array(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (emb): Embedding(127, 16)\n",
      "  (emb_drop): Dropout(p=0.25, inplace=False)\n",
      "  (emb_bn): BatchNorm1d(228, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=244, out_features=1024, bias=True)\n",
      "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (fc3): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc4): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc5): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc6): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc7): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (bn1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn6): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#model definition\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.emb = nn.Embedding(max(X_train['stock_id'])+1, 16)\n",
    "        self.emb_drop = nn.Dropout(0.25)\n",
    "        self.emb_bn = nn.BatchNorm1d(X_nn.shape[1])\n",
    "        self.fc1 = nn.Linear(16+X_nn.shape[1],1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.fc5 = nn.Linear(128, 64)\n",
    "        self.fc6 = nn.Linear(64, 32)\n",
    "        self.fc7 = nn.Linear(32, 1)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.bn1 = nn.BatchNorm1d(1024)\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.bn4 = nn.BatchNorm1d(128)\n",
    "        self.bn5 = nn.BatchNorm1d(64)\n",
    "        self.bn6 = nn.BatchNorm1d(32)\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, x_cat, x_cont):\n",
    "        x1 = self.emb(x_cat)\n",
    "        x1 = torch.flatten(x1, end_dim=1)\n",
    "        x1 = self.emb_drop(x1)\n",
    "        x2 = self.emb_bn(x_cont)\n",
    "        x = torch.cat([x1, x2], 1)\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn4(self.fc4(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn5(self.fc5(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn6(self.fc6(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc7(x)\n",
    "        \n",
    "      \n",
    "        return x\n",
    "net = Net().to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape into tensor sequences for loading\n",
    "seq = []\n",
    "for i in range(0,len(X_nn)):\n",
    "    seq.append(((X_nn_1[i],X_nn[i]),y_nn[i]))\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create trainloader\n",
    "trainloader = torch.utils.data.DataLoader(seq, batch_size=batch_size,shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set loss function and optimizer\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "steps = 30\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,patience=5, mode = 'min',factor=.9)\n",
    "\n",
    "# create a function (this my favorite choice)\n",
    "def RMPSELoss(yhat,y):\n",
    "    return torch.sqrt(torch.mean((((y-yhat)/y)**2)))\n",
    "criterion = RMPSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cba32521f7f47068801f60983b735c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "0.25068743406559\n",
      "0.001\n",
      "0.25013423991028216\n",
      "0.001\n",
      "0.25002367022097327\n",
      "0.001\n",
      "0.24931999907864205\n",
      "0.001\n",
      "0.2501960990259668\n",
      "0.001\n",
      "0.25412102485921423\n",
      "0.001\n",
      "0.2507967243616263\n",
      "0.001\n",
      "0.24908102403145232\n",
      "0.001\n",
      "0.25071049149682795\n",
      "0.001\n",
      "0.2504851904445792\n",
      "0.001\n",
      "0.2512850871941159\n",
      "0.001\n",
      "0.2496652092643292\n",
      "0.001\n",
      "0.25044456659616715\n",
      "0.001\n",
      "0.24957533088607334\n",
      "0.0009000000000000001\n",
      "0.2484195341368638\n",
      "0.0009000000000000001\n",
      "0.24652763324786284\n",
      "0.0009000000000000001\n",
      "0.247255380763564\n",
      "0.0009000000000000001\n",
      "0.24811417536497699\n",
      "0.0009000000000000001\n",
      "0.24666177461350125\n",
      "0.0009000000000000001\n",
      "0.24752713767230292\n",
      "0.0009000000000000001\n",
      "0.24528895344954518\n",
      "0.0009000000000000001\n",
      "0.24617102404775934\n",
      "0.0009000000000000001\n",
      "0.2466054292831164\n",
      "0.0009000000000000001\n",
      "0.24542382880224592\n",
      "0.0009000000000000001\n",
      "0.2466572218163069\n",
      "0.0009000000000000001\n",
      "0.2443500791780076\n",
      "0.0009000000000000001\n",
      "0.24612039988780693\n",
      "0.0009000000000000001\n",
      "0.2528683220833139\n",
      "0.0009000000000000001\n",
      "0.2527355813994694\n",
      "0.0009000000000000001\n",
      "0.2531248128344846\n",
      "0.0009000000000000001\n",
      "0.2517027561820706\n",
      "0.0009000000000000001\n",
      "0.25137244099283745\n",
      "0.0008100000000000001\n",
      "0.24931028724227425\n",
      "0.0008100000000000001\n",
      "0.25077361876151844\n",
      "0.0008100000000000001\n",
      "0.24774671089692973\n",
      "0.0008100000000000001\n",
      "0.2510979656344382\n",
      "0.0008100000000000001\n",
      "0.2473722230027472\n",
      "0.0008100000000000001\n",
      "0.24816983082813907\n",
      "0.000729\n",
      "0.24766523047205577\n",
      "0.000729\n",
      "0.24711405952783663\n",
      "0.000729\n",
      "0.24668755896635708\n",
      "0.000729\n",
      "0.24699886080283429\n",
      "0.000729\n",
      "0.24707119078392498\n",
      "0.000729\n",
      "0.2465694360389412\n",
      "0.0006561000000000001\n",
      "0.24472805652471039\n",
      "0.0006561000000000001\n",
      "0.24598915637852659\n",
      "0.0006561000000000001\n",
      "0.2458947180990344\n",
      "0.0006561000000000001\n",
      "0.24508089593165946\n",
      "0.0006561000000000001\n",
      "0.245250468282542\n",
      "0.0006561000000000001\n",
      "0.24553567381755811\n",
      "0.00059049\n",
      "0.2439308840430352\n",
      "0.00059049\n",
      "0.24364626880922108\n",
      "0.00059049\n",
      "0.2441471691267289\n",
      "0.00059049\n",
      "0.24281306580310935\n",
      "0.00059049\n",
      "0.24327653857128126\n",
      "0.00059049\n",
      "0.2434468328259712\n",
      "0.00059049\n",
      "0.2441792310360304\n",
      "0.00059049\n",
      "0.24354275958008398\n",
      "0.00059049\n",
      "0.24358410106440653\n",
      "0.00059049\n",
      "0.2415902704602356\n",
      "0.00059049\n",
      "0.24105789350069867\n",
      "0.00059049\n",
      "0.24210523323337188\n",
      "0.00059049\n",
      "0.24243323442912598\n",
      "0.00059049\n",
      "0.2422828158247427\n",
      "0.00059049\n",
      "0.24120954007384535\n",
      "0.00059049\n",
      "0.24196601523179903\n",
      "0.00059049\n",
      "0.24128554494210236\n",
      "0.000531441\n",
      "0.24115072941291288\n",
      "0.000531441\n",
      "0.24074961824144261\n",
      "0.000531441\n",
      "0.23972820439529827\n",
      "0.000531441\n",
      "0.24026650582489215\n",
      "0.000531441\n",
      "0.2410831857686965\n",
      "0.000531441\n",
      "0.24014909967615963\n",
      "0.000531441\n",
      "0.2395319879839295\n",
      "0.000531441\n",
      "0.24004458461864195\n",
      "0.000531441\n",
      "0.24032966268215797\n",
      "0.000531441\n",
      "0.2398353211645543\n",
      "0.000531441\n",
      "0.23982256903533106\n",
      "0.000531441\n",
      "0.2390726827349482\n",
      "0.000531441\n",
      "0.2403591823658132\n",
      "0.000531441\n",
      "0.23988193206972416\n",
      "0.000531441\n",
      "0.23839270972818902\n",
      "0.000531441\n",
      "0.24043394772009868\n",
      "0.000531441\n",
      "0.23984338372325664\n",
      "0.000531441\n",
      "0.23820932908952602\n",
      "0.000531441\n",
      "0.23881584746966017\n",
      "0.000531441\n",
      "0.23948705083299587\n",
      "0.000531441\n",
      "0.23770697505157465\n",
      "0.000531441\n",
      "0.23937280680368697\n",
      "0.000531441\n",
      "0.23998763123150993\n",
      "0.000531441\n",
      "0.23970086746729427\n",
      "0.000531441\n",
      "0.23785722693439795\n",
      "0.000531441\n",
      "0.24059757596677492\n",
      "0.000531441\n",
      "0.2381719261170747\n",
      "0.0004782969\n",
      "0.23746349026005592\n",
      "0.0004782969\n",
      "0.23863820962361637\n",
      "0.0004782969\n",
      "0.2374513166497212\n",
      "0.0004782969\n",
      "0.23698085288413442\n",
      "0.0004782969\n",
      "0.23668603243413433\n",
      "0.0004782969\n",
      "0.2373961420818671\n",
      "0.0004782969\n",
      "0.23596757947669036\n",
      "0.0004782969\n",
      "0.23620688189345446\n",
      "0.0004782969\n",
      "0.23599848348186825\n",
      "0.0004782969\n",
      "0.2368167869682849\n",
      "0.0004782969\n",
      "0.23623563239813727\n",
      "0.0004782969\n",
      "0.23622491809846138\n",
      "0.0004782969\n",
      "0.23823056706527163\n",
      "0.00043046721\n",
      "0.2354855936663533\n",
      "0.00043046721\n",
      "0.23521119805743673\n",
      "0.00043046721\n",
      "0.23556500976971342\n",
      "0.00043046721\n",
      "0.2354157741935046\n",
      "0.00043046721\n",
      "0.23491098917792738\n",
      "0.00043046721\n",
      "0.23564945045525762\n",
      "0.00043046721\n",
      "0.23676944639866618\n",
      "0.00043046721\n",
      "0.23464026439802738\n",
      "0.00043046721\n",
      "0.23484282981663615\n",
      "0.00043046721\n",
      "0.23519148824410457\n",
      "0.00043046721\n",
      "0.23465410766797085\n",
      "0.00043046721\n",
      "0.23516397839332298\n",
      "0.00043046721\n",
      "0.23410336159835393\n",
      "0.00043046721\n",
      "0.2351837540945925\n",
      "0.00043046721\n",
      "0.23349801138171075\n",
      "0.00043046721\n",
      "0.2357216690515363\n",
      "0.00043046721\n",
      "0.23474254834863517\n",
      "0.00043046721\n",
      "0.2343397794457807\n",
      "0.00043046721\n",
      "0.2337781227532332\n",
      "0.00043046721\n",
      "0.2350826517404074\n",
      "0.00043046721\n",
      "0.23400028380069476\n",
      "0.000387420489\n",
      "0.2332649382339697\n",
      "0.000387420489\n",
      "0.23360221014977084\n",
      "0.000387420489\n",
      "0.23438645457915022\n",
      "0.000387420489\n",
      "0.23237924133695326\n",
      "0.000387420489\n",
      "0.2334868232269328\n",
      "0.000387420489\n",
      "0.23390994631346756\n",
      "0.000387420489\n",
      "0.2336702561473321\n",
      "0.000387420489\n",
      "0.23296769039028278\n",
      "0.000387420489\n",
      "0.23324657583579586\n",
      "0.000387420489\n",
      "0.23263673447847658\n",
      "0.0003486784401\n",
      "0.23265480660494858\n",
      "0.0003486784401\n",
      "0.2316048354676479\n",
      "0.0003486784401\n",
      "0.23160187389377865\n",
      "0.0003486784401\n",
      "0.23192353800139784\n",
      "0.0003486784401\n",
      "0.23166114986490008\n",
      "0.0003486784401\n",
      "0.23142130071048783\n",
      "0.0003486784401\n",
      "0.23228481763944195\n",
      "0.0003486784401\n",
      "0.23184001832434423\n",
      "0.0003486784401\n",
      "0.23185111695360233\n",
      "0.0003486784401\n",
      "0.23152482840648625\n",
      "0.0003486784401\n",
      "0.23150542717668682\n",
      "0.0003486784401\n",
      "0.23098221735862362\n",
      "0.0003486784401\n",
      "0.2317182194975044\n",
      "0.0003486784401\n",
      "0.23132265331804971\n",
      "0.0003486784401\n",
      "0.23212728618371734\n",
      "0.0003486784401\n",
      "0.2301929182620352\n",
      "0.0003486784401\n",
      "0.2309141071875793\n",
      "0.0003486784401\n",
      "0.23162327182446144\n",
      "0.0003486784401\n",
      "0.23182110539483616\n",
      "0.0003486784401\n",
      "0.2309907229487286\n",
      "0.0003486784401\n",
      "0.23151871171692157\n",
      "0.0003486784401\n",
      "0.23080856387698373\n",
      "0.00031381059609000004\n",
      "Best Loss\n",
      "0.22980201448629653\n",
      "0.00031381059609000004\n",
      "0.2300923625634233\n",
      "0.00031381059609000004\n",
      "Best Loss\n",
      "0.22979409687193691\n",
      "0.00031381059609000004\n",
      "Best Loss\n",
      "0.22959621821506224\n",
      "0.00031381059609000004\n",
      "0.22987219499768358\n",
      "0.00031381059609000004\n",
      "0.23073083465985014\n",
      "0.00031381059609000004\n",
      "0.22979587815346303\n",
      "0.00031381059609000004\n",
      "0.22971844655829807\n",
      "0.00031381059609000004\n",
      "0.2302400532612894\n",
      "0.00031381059609000004\n",
      "0.23049308823802334\n",
      "0.00028242953648100003\n",
      "0.2298250736684665\n",
      "0.00028242953648100003\n",
      "Best Loss\n",
      "0.22907827150719548\n",
      "0.00028242953648100003\n",
      "Best Loss\n",
      "0.22877550308422767\n",
      "0.00028242953648100003\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-e3c4ca675255>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[0mcats\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcounts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m# forward + backward + optimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcounts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-57-a53f272aff5e>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x_cat, x_cont)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1688\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1689\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1690\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1691\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1692\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net.load_state_dict(torch.load('models/nn.pt'), strict=False)\n",
    "net.train()\n",
    "#model training\n",
    "running_loss_min = 0.23\n",
    "import time\n",
    "start_time = time.time()\n",
    "for epoch in tqdm(range(500)):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    running_val_loss = 0.0\n",
    "    print(optimizer.param_groups[0]['lr'])\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        (cats,counts), preds = data\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(cats.to(device),counts.to(device))\n",
    "        loss = criterion(outputs.reshape(1,-1), preds.reshape(1,-1).to(device))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    if (running_loss/(i + 1)) < running_loss_min:\n",
    "        torch.save(net.state_dict(), 'models/nn.pt')\n",
    "        running_loss_min = (running_loss/(i + 1))\n",
    "        print('Best Loss')\n",
    "    scheduler.step(running_loss)\n",
    "    print(running_loss/(i + 1))\n",
    "print('Finished Training')\n",
    "print(\"time\",(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert training date to tensors\n",
    "X_test_nn = torch.FloatTensor(np.array(X_test[columns]))\n",
    "X_test_nn_1 = X_test[['stock_id']].copy().values.astype(np.int64)\n",
    "y_test_nn = torch.FloatTensor(np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape into tensor sequences for loading\n",
    "testseq = []\n",
    "for i in range(0,len(X_test_nn)):\n",
    "    testseq.append(((X_test_nn_1[i],X_test_nn[i]),y_test_nn[i]))\n",
    "    i = i + 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10724"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create trainloader\n",
    "testloader = torch.utils.data.DataLoader(testseq, batch_size=len(testseq),shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a99fc3cb8c14f9b8ba1600f6ae32b16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "net.load_state_dict(torch.load('models/nn.pt'), strict=False)\n",
    "net_eval = net.eval().cpu()\n",
    "nn_preds = []\n",
    "for (x_cat, x_cont), y_ in tqdm(testloader):\n",
    "    nn_preds = net_eval(x_cat,x_cont).detach().cpu().numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " R2 score: 0.843, RMSPE: 0.207\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "def rmspe(y_true, y_pred):\n",
    "    return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))\n",
    "R2 = round(r2_score(y_true = y_test, y_pred = nn_preds),3)\n",
    "RMSPE = round(rmspe(y_true = y_test, y_pred = nn_preds),3)\n",
    "print(f' R2 score: {R2}, RMSPE: {RMSPE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'models/nn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00644385, 0.00226229, 0.00285133, ..., 0.00199356, 0.00360787,\n",
       "       0.00332407], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00567519, 0.00241666, 0.00253724, ..., 0.00194683, 0.00319025,\n",
       "       0.00320705], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_preds = (xg_preds+nn_preds)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " R2 score: 0.88, RMSPE: 0.204\n"
     ]
    }
   ],
   "source": [
    "R2 = round(r2_score(y_true = y_test, y_pred = comb_preds),3)\n",
    "RMSPE = round(rmspe(y_true = y_test, y_pred = comb_preds),3)\n",
    "print(f' R2 score: {R2}, RMSPE: {RMSPE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
